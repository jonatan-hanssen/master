@article{gradcam,
   title={Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization},
   volume={128},
   ISSN={1573-1405},
   url={http://dx.doi.org/10.1007/s11263-019-01228-7},
   DOI={10.1007/s11263-019-01228-7},
   number={2},
   journal={International Journal of Computer Vision},
   publisher={Springer Science and Business Media LLC},
   author={Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
   year={2019},
   month=oct, pages={336–359}
}

@article{rosenblatt,
  added-at = {2017-07-19T15:29:59.000+0200},
  author = {Rosenblatt, F.},
  biburl = {https://www.bibsonomy.org/bibtex/214ee8da21c66cd4d00d7ab6eca2d96a9/andreashdez},
  citeulike-article-id = {13697582},
  citeulike-linkout-0 = {http://dx.doi.org/10.1037/h0042519},
  doi = {10.1037/h0042519},
  interhash = {dc0cef9dc06033a04f525efdcde7a660},
  intrahash = {14ee8da21c66cd4d00d7ab6eca2d96a9},
  issn = {0033-295X},
  journal = {Psychological Review},
  keywords = {imported},
  number = 6,
  pages = {386--408},
  posted-at = {2016-05-02 20:23:36},
  priority = {2},
  timestamp = {2017-07-19T15:31:02.000+0200},
  title = {{The perceptron: A probabilistic model for information storage and organization in the brain.}},
  url = {http://dx.doi.org/10.1037/h0042519},
  volume = 65,
  year = 1958
}

@book{mitchell,
  added-at = {2022-09-08T09:41:39.000+0200},
  author = {Mitchell, Tom M},
  biburl = {https://www.bibsonomy.org/bibtex/2ea9f893d9d19c182bcf2822eb590fe4f/msteininger},
  interhash = {479a66c32badb3a455fbdcf8e6633a5d},
  intrahash = {ea9f893d9d19c182bcf2822eb590fe4f},
  keywords = {book ml},
  number = 9,
  publisher = {McGraw-hill New York},
  timestamp = {2022-09-08T17:32:10.000+0200},
  title = {Machine learning},
  volume = 1,
  year = 1997
}

@ARTICLE{tingsim,
  title    = "Machine learning in medicine: what clinicians should know",
  author   = "Ting Sim, Jordan Zheng and Fong, Qi Wei and Huang, Weimin and
              Tan, Cher Heng",
  abstract = "With the advent of artificial intelligence (AI), machines are
              increasingly being used to complete complicated tasks, yielding
              remarkable results. Machine learning (ML) is the most relevant
              subset of AI in medicine, which will soon become an integral part
              of our everyday practice. Therefore, physicians should acquaint
              themselves with ML and AI, and their role as an enabler rather
              than a competitor. Herein, we introduce basic concepts and terms
              used in AI and ML, and aim to demystify commonly used AI/ML
              algorithms such as learning methods including neural
              networks/deep learning, decision tree and application domain in
              computer vision and natural language processing through specific
              examples. We discuss how machines are already being used to
              augment the physician's decision-making process, and postulate
              the potential impact of ML on medical practice and medical
              research based on its current capabilities and known limitations.
              Moreover, we discuss the feasibility of full machine autonomy in
              medicine.",
  journal  = "Singapore Med J",
  volume   =  64,
  number   =  2,
  pages    = "91--97",
  month    =  may,
  year     =  2021,
  address  = "India",
  keywords = "Algorithms; artificial intelligence; deep learning; machine
              learning; neural networks",
  language = "en"
}

@article{dlmed,
author = {Alvin Rajkomar  and Jeffrey Dean  and Isaac Kohane },
title = {Machine Learning in Medicine},
journal = {New England Journal of Medicine},
volume = {380},
number = {14},
pages = {1347-1358},
year = {2019},
doi = {10.1056/NEJMra1814259},
URL = {https://www.nejm.org/doi/full/10.1056/NEJMra1814259},
eprint = {https://www.nejm.org/doi/pdf/10.1056/NEJMra1814259},
abstract = { In this view of the future of medicine, patient–provider interactions are informed and supported by massive amounts of data from interactions with similar patients. These data are collected and curated to provide the latest evidence-based assessment and recommendations. }
}

@article{hyperkvasir,
  title = {{HyperKvasir, a comprehensive multi-class
    image and video dataset for gastrointestinal endoscopy}},
  author = {
    Borgli, Hanna and Thambawita, Vajira and
    Smedsrud, Pia H and Hicks, Steven and Jha, Debesh and
    Eskeland, Sigrun L and Randel, Kristin Ranheim and
    Pogorelov, Konstantin and Lux, Mathias and
    Nguyen, Duc Tien Dang and Johansen, Dag and
    Griwodz, Carsten and Stensland, H{\aa}kon K and
    Garcia-Ceja, Enrique and Schmidt, Peter T and
    Hammer, Hugo L and Riegler, Michael A and
    Halvorsen, P{\aa}l and de Lange, Thomas
  },
  doi = {10.1038/s41597-020-00622-y},
  issn = {2052-4463},
  journal = {Scientific Data},
  number = {1},
  pages = {283},
  url = {https://doi.org/10.1038/s41597-020-00622-y},
  volume = {7},
  year = {2020}
}

@misc{cam,
      title={Learning Deep Features for Discriminative Localization}, 
      author={Bolei Zhou and Aditya Khosla and Agata Lapedriza and Aude Oliva and Antonio Torralba},
      year={2015},
      eprint={1512.04150},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{lrp,
    doi = {10.1371/journal.pone.0130140},
    author = {Bach, Sebastian AND Binder, Alexander AND Montavon, Grégoire AND Klauschen, Frederick AND Müller, Klaus-Robert AND Samek, Wojciech},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation},
    year = {2015},
    month = {07},
    volume = {10},
    url = {https://doi.org/10.1371/journal.pone.0130140},
    pages = {1-46},
    abstract = {Understanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert. Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision. This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers. We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest. We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package.},
    number = {7},
}

@article{xaioverview,
title = {Explainable artificial intelligence (XAI) in deep learning-based medical image analysis},
journal = {Medical Image Analysis},
volume = {79},
pages = {102470},
year = {2022},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2022.102470},
url = {https://www.sciencedirect.com/science/article/pii/S1361841522001177},
author = {Bas H.M. {van der Velden} and Hugo J. Kuijf and Kenneth G.A. Gilhuijs and Max A. Viergever},
keywords = {Explainable artificial intelligence, Interpretable deep learning, Medical image analysis, Deep learning, Survey},
abstract = {With an increase in deep learning-based methods, the call for explainability of such methods grows, especially in high-stakes decision making areas such as medical image analysis. This survey presents an overview of explainable artificial intelligence (XAI) used in deep learning-based medical image analysis. A framework of XAI criteria is introduced to classify deep learning-based medical image analysis methods. Papers on XAI techniques in medical image analysis are then surveyed and categorized according to the framework and according to anatomical location. The paper concludes with an outlook of future opportunities for XAI in medical image analysis.}
}

@article{xaisurvey,
  title={Survey of explainable artificial intelligence techniques for biomedical imaging with deep neural networks},
  author={Sajid Nazir and Diane M. Dickson and Muhammad Usman Akram},
  journal={Computers in biology and medicine},
  year={2023},
  volume={156},
  pages={
          106668
        },
  url={https://api.semanticscholar.org/CorpusID:257067347}
}

@misc{intriguing,
      title={Intriguing properties of neural networks}, 
      author={Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian Goodfellow and Rob Fergus},
      year={2014},
      eprint={1312.6199},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{performance,
  author    = {Dargan, Shaveta and Kumar, Munish and Ayyagari, Maruthi Rohit and Kumar, Gulshan},
  title     = {A Survey of Deep Learning and Its Applications: A New Paradigm to Machine Learning},
  journal   = {Archives of Computational Methods in Engineering},
  volume    = {27},
  number    = {4},
  pages     = {1071--1092},
  year      = {2020},
  month     = {09},
  day       = {01},
  doi       = {10.1007/s11831-019-09344-w},
  issn      = {1886-1784},
  abstract  = {Nowadays, deep learning is a current and a stimulating field of machine learning. Deep learning is the most effective, supervised, time and cost efficient machine learning approach. Deep learning is not a restricted learning approach, but it abides various procedures and topographies which can be applied to an immense speculum of complicated problems. The technique learns the illustrative and differential features in a very stratified way. Deep learning methods have made a significant breakthrough with appreciable performance in a wide variety of applications with useful security tools. It is considered to be the best choice for discovering complex architecture in high-dimensional data by employing back propagation algorithm. As deep learning has made significant advancements and tremendous performance in numerous applications, the widely used domains of deep learning are business, science and government which further includes adaptive testing, biological image classification, computer vision, cancer detection, natural language processing, object detection, face recognition, handwriting recognition, speech recognition, stock market analysis, smart city and many more. This paper focuses on the concepts of deep learning, its basic and advanced architectures, techniques, motivational aspects, characteristics and the limitations. The paper also presents the major differences between the deep learning, classical machine learning and conventional learning approaches and the major challenges ahead. The main intention of this paper is to explore and present chronologically, a comprehensive survey of the major applications of deep learning covering variety of areas, study of the techniques and architectures used and further the contribution of that respective application in the real world. Finally, the paper ends with the conclusion and future aspects.},
  url       = {https://doi.org/10.1007/s11831-019-09344-w}
}

@misc{nullspace,
      title={Outlier Detection through Null Space Analysis of Neural Networks}, 
      author={Matthew Cook and Alina Zare and Paul Gader},
      year={2020},
      eprint={2007.01263},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{energy,
      title={Energy-based Out-of-distribution Detection}, 
      author={Weitang Liu and Xiaoyun Wang and John D. Owens and Yixuan Li},
      year={2021},
      eprint={2010.03759},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{vos,
      title={VOS: Learning What You Don't Know by Virtual Outlier Synthesis}, 
      author={Xuefeng Du and Zhaoning Wang and Mu Cai and Yixuan Li},
      year={2022},
      eprint={2202.01197},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{oodoverview,
      title={Generalized Out-of-Distribution Detection: A Survey}, 
      author={Jingkang Yang and Kaiyang Zhou and Yixuan Li and Ziwei Liu},
      year={2024},
      eprint={2110.11334},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{doshivelez,
      title={Towards A Rigorous Science of Interpretable Machine Learning}, 
      author={Finale Doshi-Velez and Been Kim},
      year={2017},
      eprint={1702.08608},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@book{molnar,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  year       = {2022},
  subtitle   = {A Guide for Making Black Box Models Explainable},
  edition    = {2},
  url        = {https://christophm.github.io/interpretable-ml-book},
  publisher  = {Independently published}
}

@misc{gradnorm,
      title={On the Importance of Gradients for Detecting Distributional Shifts in the Wild}, 
      author={Rui Huang and Andrew Geng and Yixuan Li},
      year={2021},
      eprint={2110.00218},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{react,
      title={ReAct: Out-of-distribution Detection With Rectified Activations}, 
      author={Yiyou Sun and Chuan Guo and Yixuan Li},
      year={2021},
      eprint={2111.12797},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@Article{diagnostic,
AUTHOR = {Thunold, Håvard Horgen and Riegler, Michael A. and Yazidi, Anis and Hammer, Hugo L.},
TITLE = {A Deep Diagnostic Framework Using Explainable Artificial Intelligence and Clustering},
JOURNAL = {Diagnostics},
VOLUME = {13},
YEAR = {2023},
NUMBER = {22},
ARTICLE-NUMBER = {3413},
URL = {https://www.mdpi.com/2075-4418/13/22/3413},
PubMedID = {37998548},
ISSN = {2075-4418},
ABSTRACT = {An important part of diagnostics is to gain insight into properties that characterize a disease. Machine learning has been used for this purpose, for instance, to identify biomarkers in genomics. However, when patient data are presented as images, identifying properties that characterize a disease becomes far more challenging. A common strategy involves extracting features from the images and analyzing their occurrence in healthy versus pathological images. A limitation of this approach is that the ability to gain new insights into the disease from the data is constrained by the information in the extracted features. Typically, these features are manually extracted by humans, which further limits the potential for new insights. To overcome these limitations, in this paper, we propose a novel framework that provides insights into diseases without relying on handcrafted features or human intervention. Our framework is based on deep learning (DL), explainable artificial intelligence (XAI), and clustering. DL is employed to learn deep patterns, enabling efficient differentiation between healthy and pathological images. Explainable artificial intelligence (XAI) visualizes these patterns, and a novel “explanation-weighted” clustering technique is introduced to gain an overview of these patterns across multiple patients. We applied the method to images from the gastrointestinal tract. In addition to real healthy images and real images of polyps, some of the images had synthetic shapes added to represent other types of pathologies than polyps. The results show that our proposed method was capable of organizing the images based on the reasons they were diagnosed as pathological, achieving high cluster quality and a rand index close to or equal to one.},
DOI = {10.3390/diagnostics13223413}
}


@InProceedings{occlusion,
author="Zeiler, Matthew D.
and Fergus, Rob",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Visualizing and Understanding Convolutional Networks",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="818--833",
abstract="Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.",
isbn="978-3-319-10590-1"
}

@misc{subspace,
      title={Out-Of-Distribution Detection With Subspace Techniques And Probabilistic Modeling Of Features}, 
      author={Ibrahima Ndiour and Nilesh Ahuja and Omesh Tickoo},
      year={2020},
      eprint={2012.04250},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{nusa,
      title={Outlier Detection through Null Space Analysis of Neural Networks}, 
      author={Matthew Cook and Alina Zare and Paul Gader},
      year={2020},
      eprint={2007.01263},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{vim,
      title={ViM: Out-Of-Distribution with Virtual-logit Matching}, 
      author={Haoqi Wang and Zhizhong Li and Litong Feng and Wayne Zhang},
      year={2022},
      eprint={2203.10807},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{gdpr,
  title = {Article 71: European Data Protection Board},
  author = {{European Union}},
  year = {2016},
  url = {https://www.privacy-regulation.eu/en/r71.htm},
  note = {Accessed: February 13, 2024}
}

@article{lenet5,
author = {Lecun, Yann and Bottou, Leon and Bengio, Y. and Haffner, Patrick},
year = {1998},
month = {12},
pages = {2278 - 2324},
title = {Gradient-Based Learning Applied to Document Recognition},
volume = {86},
journal = {Proceedings of the IEEE},
doi = {10.1109/5.726791}
}


@article{ooddl,
AUTHOR = {Cui, Peng and Wang, Jinjia},
TITLE = {Out-of-Distribution (OOD) Detection Based on Deep Learning: A Review},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {21},
ARTICLE-NUMBER = {3500},
URL = {https://www.mdpi.com/2079-9292/11/21/3500},
ISSN = {2079-9292},
ABSTRACT = {Out-of-Distribution (OOD) detection separates ID (In-Distribution) data and OOD data from input data through a model. This problem has attracted increasing attention in the area of machine learning. OOD detection has achieved good intrusion detection, fraud detection, system health monitoring, sensor network event detection, and ecosystem interference detection. The method based on deep learning is the most studied in OOD detection. In this paper, related basic information on OOD detection based on deep learning is described, and we categorize methods according to the training data. OOD detection is divided into supervised, semisupervised, and unsupervised. Where supervised data are used, the methods are categorized according to technical means: model-based, distance-based, and density-based. Each classification is introduced with background, examples, and applications. In addition, we present the latest applications of OOD detection based on deep learning and the problems and expectations in this field.},
DOI = {10.3390/electronics11213500}
}

@misc{adversarial,
      title={Explaining and Harnessing Adversarial Examples}, 
      author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
      year={2015},
      eprint={1412.6572},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{odin,
      title={Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks}, 
      author={Shiyu Liang and Yixuan Li and R. Srikant},
      year={2020},
      eprint={1706.02690},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{oodbaseline,
      title={A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks}, 
      author={Dan Hendrycks and Kevin Gimpel},
      year={2018},
      eprint={1610.02136},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}
