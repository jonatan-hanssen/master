@article{gradcam,
   title={Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization},
   volume={128},
   ISSN={1573-1405},
   url={http://dx.doi.org/10.1007/s11263-019-01228-7},
   DOI={10.1007/s11263-019-01228-7},
   number={2},
   journal={International Journal of Computer Vision},
   publisher={Springer Science and Business Media LLC},
   author={Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
   year={2019},
   month=oct, pages={336–359} }

@misc{cam,
      title={Learning Deep Features for Discriminative Localization}, 
      author={Bolei Zhou and Aditya Khosla and Agata Lapedriza and Aude Oliva and Antonio Torralba},
      year={2015},
      eprint={1512.04150},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{lrp,
    doi = {10.1371/journal.pone.0130140},
    author = {Bach, Sebastian AND Binder, Alexander AND Montavon, Grégoire AND Klauschen, Frederick AND Müller, Klaus-Robert AND Samek, Wojciech},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation},
    year = {2015},
    month = {07},
    volume = {10},
    url = {https://doi.org/10.1371/journal.pone.0130140},
    pages = {1-46},
    abstract = {Understanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert. Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision. This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers. We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest. We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package.},
    number = {7},
}

@article{xaioverview,
title = {Explainable artificial intelligence (XAI) in deep learning-based medical image analysis},
journal = {Medical Image Analysis},
volume = {79},
pages = {102470},
year = {2022},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2022.102470},
url = {https://www.sciencedirect.com/science/article/pii/S1361841522001177},
author = {Bas H.M. {van der Velden} and Hugo J. Kuijf and Kenneth G.A. Gilhuijs and Max A. Viergever},
keywords = {Explainable artificial intelligence, Interpretable deep learning, Medical image analysis, Deep learning, Survey},
abstract = {With an increase in deep learning-based methods, the call for explainability of such methods grows, especially in high-stakes decision making areas such as medical image analysis. This survey presents an overview of explainable artificial intelligence (XAI) used in deep learning-based medical image analysis. A framework of XAI criteria is introduced to classify deep learning-based medical image analysis methods. Papers on XAI techniques in medical image analysis are then surveyed and categorized according to the framework and according to anatomical location. The paper concludes with an outlook of future opportunities for XAI in medical image analysis.}
}


@Article{oodoverview,
AUTHOR = {Cui, Peng and Wang, Jinjia},
TITLE = {Out-of-Distribution (OOD) Detection Based on Deep Learning: A Review},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {21},
ARTICLE-NUMBER = {3500},
URL = {https://www.mdpi.com/2079-9292/11/21/3500},
ISSN = {2079-9292},
ABSTRACT = {Out-of-Distribution (OOD) detection separates ID (In-Distribution) data and OOD data from input data through a model. This problem has attracted increasing attention in the area of machine learning. OOD detection has achieved good intrusion detection, fraud detection, system health monitoring, sensor network event detection, and ecosystem interference detection. The method based on deep learning is the most studied in OOD detection. In this paper, related basic information on OOD detection based on deep learning is described, and we categorize methods according to the training data. OOD detection is divided into supervised, semisupervised, and unsupervised. Where supervised data are used, the methods are categorized according to technical means: model-based, distance-based, and density-based. Each classification is introduced with background, examples, and applications. In addition, we present the latest applications of OOD detection based on deep learning and the problems and expectations in this field.},
DOI = {10.3390/electronics11213500}
}

@misc{doshivelez,
      title={Towards A Rigorous Science of Interpretable Machine Learning}, 
      author={Finale Doshi-Velez and Been Kim},
      year={2017},
      eprint={1702.08608},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@book{molnar,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  year       = {2022},
  subtitle   = {A Guide for Making Black Box Models Explainable},
  edition    = {2},
  url        = {https://christophm.github.io/interpretable-ml-book}
}

@online{gdpr,
  title = {Article 71: European Data Protection Board},
  author = {{European Union}},
  year = {2016},
  url = {https://www.privacy-regulation.eu/en/r71.htm},
  note = {Accessed: February 13, 2024}
}

@article{lenet5,
author = {Lecun, Yann and Bottou, Leon and Bengio, Y. and Haffner, Patrick},
year = {1998},
month = {12},
pages = {2278 - 2324},
title = {Gradient-Based Learning Applied to Document Recognition},
volume = {86},
journal = {Proceedings of the IEEE},
doi = {10.1109/5.726791}
}
